{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For following a second Drone\n",
    "#Must have second drone in sights of Mambo Drone\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import zipfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_file = \"./traffic-signs-data/train.p\"\n",
    "validation_file= \"./traffic-signs-data/valid.p\"\n",
    "testing_file = \"./traffic-signs-data/valid.p\"\n",
    "\n",
    "with open(training_file, mode = 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(testing_file, mode = 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "with open(validation_file, mode = 'rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "    \n",
    "\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "X_valid, y_valid = valid['features'], valid['features']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples =  34799\n",
      "Number of testing examples =  4410\n",
      "Image shape =  (32, 32, 3)\n",
      "Number of classes =  43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "n_valid = len(X_valid)\n",
    "\n",
    "#Image shape and dimensions\n",
    "image_shape = X_train[0].shape\n",
    "#Number of classes and labels\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples = \", n_train)\n",
    "print(\"Number of testing examples = \", n_test)\n",
    "print(\"Image shape = \", image_shape)\n",
    "print(\"Number of classes = \", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_gray (34799, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the Dataset \n",
    "\n",
    "#Grayscale \n",
    "\n",
    "X_train_gray = np.sum(X_train / 3, axis = 3, keepdims=True)\n",
    "X_valid_gray = np.sum(X_valid / 3, axis = 3, keepdims=True)\n",
    "X_test_gray = np.sum(X_test / 3, axis = 3, keepdims= True)\n",
    "print(\"X_train_gray\", X_train_gray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.354081335648\n"
     ]
    }
   ],
   "source": [
    "# Normalize images \n",
    "\n",
    "X_train_normalize = ((X_train_gray - 128) / 128)\n",
    "X_test_normalize = ((X_test_gray - 128) / 128)\n",
    "X_valid_normalize = ((X_valid_gray - 128) / 128)\n",
    "\n",
    "print(np.mean(X_train_normalize))\n",
    "X_valid = X_valid_normalize\n",
    "X_train = X_train_normalize\n",
    "X_test = X_test_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Image Augmentation Functions \n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sharpen_image(img):\n",
    "    gb = cv2.GaussianBlur(img, (5,5), 20.0)\n",
    "    return cv2.addWeighted(img, 2, gb, -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_random(img):\n",
    "    np.random.seed(43)\n",
    "    rand_x = np.random.randint(-5, 5)\n",
    "    rand_y = np.random.randint(-5, 5)\n",
    "    translation_matrix = np.float32([ [1,0,rand_x], [0,1,rand_y]])\n",
    "    return cv2.warpAffine(img, translation_matrix, (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise(img):\n",
    "    noisy_image = skimage.util.random_noise(img, mode='gaussian', seed=None, clip=True) \n",
    "    return np.asarray(noisy_image, dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_all(data):\n",
    "    for x in data:\n",
    "        rand_number = random.randint(0, 6)\n",
    "        if rand_number == 0 or rand_number == 1:\n",
    "            x = add_noise(x)\n",
    "        if rand_number == 2:\n",
    "            x = translate_random(x)\n",
    "        if rand_number == 3:\n",
    "            x = sharpen_image(x)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "# keras.utils.to_categorical(y, num_classes=None)\n",
    "# X_train = augment_all(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamestouri/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), input_shape=(32, 32, 1..., activation=\"relu\", strides=(1, 1))`\n",
      "/Users/jamestouri/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(100, (3, 3), activation=\"relu\", strides=(1, 1))`\n",
      "/Users/jamestouri/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(150, (5, 5), activation=\"relu\", strides=(1, 1))`\n",
      "/Users/jamestouri/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(250, (2, 2), activation=\"relu\", strides=(1, 1))`\n",
      "/Users/jamestouri/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1000, (2, 2), activation=\"relu\", strides=(1, 1))`\n",
      "/Users/jamestouri/anaconda/lib/python3.5/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 34799 samples\n",
      "Epoch 1/1\n",
      "34799/34799 [==============================] - 403s - loss: 12.6091 - val_loss: 12.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128985550>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lanet Architecture\n",
    "model = Sequential()\n",
    "#Input: 32, 32, 1  Output: 30, 30, 10\n",
    "# model.add(Convolution2D(input_shape=(32, 32, 1)))\n",
    "model.add(Convolution2D(10, 3, 3, subsample=(1, 1), activation='relu' , input_shape=(32, 32, 1)))\n",
    "model.add(Dropout(0.9))\n",
    "#Input: 30, 30, 10 Output: 28, 28, 100 \n",
    "model.add(Convolution2D(100, 3, 3, subsample=(1, 1), activation='relu'))\n",
    "#Max Pooling Input: 28, 28, 100 Output 14, 14, 100\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "#Input: 14, 14, 100 Output: 10, 10, 150\n",
    "model.add(Convolution2D(150, 5, 5, subsample=(1,1), activation= 'relu'))\n",
    "model.add(Dropout(0.8))\n",
    "#Max Pooling Input 10, 10, 150 Output: 5, 5, 150\n",
    "model.add(MaxPooling2D(2,2))\n",
    "#Input 5, 5, 150 Output 4, 4, 250\n",
    "model.add(Convolution2D(250, 2, 2,subsample=(1,1), activation= 'relu'))\n",
    "model.add(Dropout(0.7))\n",
    "#Max Pooling Input 4, 4, 250 Output: 2, 2, 250\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "#Input 2, 2, 250 Output: 1, 1, 1000\n",
    "model.add(Convolution2D(1000, 2, 2,subsample=(1,1), activation= 'relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Dense(300))\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(n_classes))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X_train, y_train, nb_epoch= 1, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
