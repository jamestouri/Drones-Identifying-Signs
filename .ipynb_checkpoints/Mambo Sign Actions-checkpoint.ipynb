{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For following a second Drone\n",
    "#Must have second drone in sights of Mambo Drone\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import zipfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_file = \"./traffic-signs-data/train.p\"\n",
    "validation_file= \"./traffic-signs-data/valid.p\"\n",
    "testing_file = \"./traffic-signs-data/valid.p\"\n",
    "\n",
    "with open(training_file, mode = 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(testing_file, mode = 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "with open(validation_file, mode = 'rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "    \n",
    "\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "X_valid, y_test = valid['features'], valid['features']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples =  34799\n",
      "Number of testing examples =  4410\n",
      "Image shape =  (32, 32, 3)\n",
      "Number of classes =  43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "n_valid = len(X_valid)\n",
    "\n",
    "#Image shape and dimensions\n",
    "image_shape = X_train[0].shape\n",
    "#Number of classes and labels\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples = \", n_train)\n",
    "print(\"Number of testing examples = \", n_test)\n",
    "print(\"Image shape = \", image_shape)\n",
    "print(\"Number of classes = \", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_gray (34799, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the Dataset \n",
    "\n",
    "#Grayscale \n",
    "\n",
    "X_train_gray = np.sum(X_train / 3, axis = 3, keepdims=True)\n",
    "X_valid_gray = np.sum(X_valid / 3, axis = 3, keepdims=True)\n",
    "X_test_gray = np.sum(X_test / 3, axis = 3, keepdims= True)\n",
    "print(\"X_train_gray\", X_train_gray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.354081335648\n"
     ]
    }
   ],
   "source": [
    "# Normalize images \n",
    "\n",
    "X_train_normalize = ((X_train_gray - 128) / 128)\n",
    "X_test_normalize = ((X_test_gray - 128) / 128)\n",
    "\n",
    "print(np.mean(X_train_normalize))\n",
    "\n",
    "X_train = X_train_normalize\n",
    "X_test = X_test_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Image Augmentation Functions \n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sharpen_image(img):\n",
    "    gb = cv2.GaussianBlur(img, (5,5), 20.0)\n",
    "    return cv2.addWeighted(img, 2, gb, -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_random(img):\n",
    "    np.random.seed(43)\n",
    "    rand_x = np.random.randint(-5, 5)\n",
    "    rand_y = np.random.randint(-5, 5)\n",
    "    translation_matrix = np.float32([ [1,0,rand_x], [0,1,rand_y]])\n",
    "    return cv2.warpAffine(img, translation_matrix, (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise(img):\n",
    "    noisy_image = skimage.util.random_noise(img, mode='gaussian', seed=None, clip=True) \n",
    "    return np.asarray(noisy_image, dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_all(data):\n",
    "    for x in data:\n",
    "        rand_number = random.randint(0, 6)\n",
    "        if rand_number == 0 or rand_number == 1:\n",
    "            x = add_noise(x)\n",
    "        if rand_number == 2:\n",
    "            x = translate_random(x)\n",
    "        if rand_number == 3:\n",
    "            x = sharpen_image(x)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_train = augment_all(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamestouri/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", strides=(2, 2), input_shape=(32, 32, 1...)`\n"
     ]
    }
   ],
   "source": [
    "#Lanet Architecture\n",
    "model = Sequential()\n",
    "#Input: 32, 32, 1  Output: 30, 30, 10\n",
    "# model.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 1)))\n",
    "model.add(Convolution2D(10, 3, 3, subsample=(2, 2), activation='relu' , input_shape=(32, 32, 1)))\n",
    "model.add(Dropout(0.9))\n",
    "#Input: 30, 30, 10 Output: 28, 28, 100 \n",
    "model.add(Convolution2D(100, 3, 3, subsample=(2, 2), activation='relu'))\n",
    "#Max Pooling Input: 28, 28, 100 Output 14, 14, 100\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
