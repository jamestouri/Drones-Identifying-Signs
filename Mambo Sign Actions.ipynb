{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For following a second Drone\n",
    "#Must have second drone in sights of Mambo Drone\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import zipfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_file = \"./traffic-signs-data/train.p\"\n",
    "validation_file= \"./traffic-signs-data/valid.p\"\n",
    "testing_file = \"./traffic-signs-data/valid.p\"\n",
    "\n",
    "with open(training_file, mode = 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(testing_file, mode = 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "with open(validation_file, mode = 'rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "    \n",
    "\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "X_valid, y_valid = valid['features'], valid['features']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples =  34799\n",
      "Number of testing examples =  4410\n",
      "Image shape =  (32, 32, 3)\n",
      "Number of classes =  43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "n_valid = len(X_valid)\n",
    "\n",
    "#Image shape and dimensions\n",
    "image_shape = X_train[0].shape\n",
    "#Number of classes and labels\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples = \", n_train)\n",
    "print(\"Number of testing examples = \", n_test)\n",
    "print(\"Image shape = \", image_shape)\n",
    "print(\"Number of classes = \", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_gray (34799, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the Dataset \n",
    "\n",
    "#Grayscale \n",
    "\n",
    "X_train_gray = np.sum(X_train / 3, axis = 3, keepdims=True)\n",
    "X_valid_gray = np.sum(X_valid / 3, axis = 3, keepdims=True)\n",
    "X_test_gray = np.sum(X_test / 3, axis = 3, keepdims= True)\n",
    "print(\"X_train_gray\", X_train_gray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.354081335648\n",
      "-0.347215411128\n"
     ]
    }
   ],
   "source": [
    "# Normalize images \n",
    "X_train_normalize = ((X_train_gray - 128) / 128)\n",
    "X_valid_normalize = ((X_valid_gray - 128) / 128)\n",
    "X_test_normalize = ((X_test_gray - 128) / 128)\n",
    "\n",
    "print(np.mean(X_train_normalize))\n",
    "print(np.mean(X_test_normalize))\n",
    "\n",
    "X_train = X_train_normalize\n",
    "X_valid = X_valid_normalize\n",
    "X_test = X_test_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Image Augmentation Functions \n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sharpen_image(img):\n",
    "    gb = cv2.GaussianBlur(img, (5,5), 20.0)\n",
    "    return cv2.addWeighted(img, 2, gb, -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_random(img):\n",
    "    np.random.seed(42)\n",
    "    rand_x = np.random.randint(-5,5)\n",
    "    rand_y = np.random.randint(-5,5)\n",
    "    translation_matrix = np.float32([ [1,0,rand_x], [0,1,rand_y]])\n",
    "    return cv2.warpAffine(img, translation_matrix, (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise(img):\n",
    "    noisy_image = skimage.util.random_noise(img, mode='gaussian', seed=None, clip=True) \n",
    "    return np.asarray(noisy_image, dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_all(data):\n",
    "    for x in data:\n",
    "        rand_number = random.randint(0, 6)\n",
    "        if rand_number == 0 or 1:\n",
    "            x = sharpen_image(x)\n",
    "        if rand_number == 2:\n",
    "            x = translate_random(x)\n",
    "        if rand_number == 3:\n",
    "            x = add_noise(x)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(32, 32, 1..., strides=(1, 1))`\n",
      "/home/carnd/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(100, (3, 3), activation=\"relu\", strides=(1, 1))`\n",
      "/home/carnd/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(150, (5, 5), activation=\"relu\", strides=(1, 1))`\n",
      "/home/carnd/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(250, (2, 2), activation=\"relu\", strides=(1, 1))`\n",
      "/home/carnd/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1000, (2, 2), activation=\"relu\", strides=(1, 1))`\n",
      "/home/carnd/anaconda3/lib/python3.5/site-packages/keras/models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27839 samples, validate on 6960 samples\n",
      "Epoch 1/15\n",
      "27839/27839 [==============================] - 262s - loss: 10.3943 - val_loss: 10.7210\n",
      "Epoch 2/15\n",
      "27839/27839 [==============================] - 258s - loss: 10.5881 - val_loss: 10.7210\n",
      "Epoch 3/15\n",
      "27839/27839 [==============================] - 258s - loss: 10.5886 - val_loss: 10.7210\n",
      "Epoch 4/15\n",
      "27839/27839 [==============================] - 258s - loss: 10.7994 - val_loss: 12.8492\n",
      "Epoch 5/15\n",
      "27839/27839 [==============================] - 258s - loss: 12.7655 - val_loss: 12.8241\n",
      "Epoch 6/15\n",
      "27839/27839 [==============================] - 258s - loss: 12.7659 - val_loss: 12.8241\n",
      "Epoch 7/15\n",
      "27839/27839 [==============================] - 258s - loss: 12.7659 - val_loss: 12.8241\n",
      "Epoch 8/15\n",
      "27839/27839 [==============================] - 258s - loss: 12.7659 - val_loss: 12.8241\n",
      "Epoch 9/15\n",
      "27839/27839 [==============================] - 258s - loss: 12.7659 - val_loss: 12.8241\n",
      "Epoch 10/15\n",
      "27839/27839 [==============================] - 259s - loss: 12.7659 - val_loss: 12.8241\n",
      "Epoch 11/15\n",
      "27839/27839 [==============================] - 258s - loss: 12.7659 - val_loss: 12.8241\n",
      "Epoch 12/15\n",
      "27839/27839 [==============================] - 259s - loss: 12.7659 - val_loss: 12.8241\n",
      "Epoch 13/15\n",
      "27839/27839 [==============================] - 258s - loss: 12.7659 - val_loss: 12.8241\n",
      "Epoch 14/15\n",
      "27839/27839 [==============================] - 258s - loss: 12.7659 - val_loss: 12.8241\n",
      "Epoch 15/15\n",
      "27839/27839 [==============================] - 259s - loss: 12.7659 - val_loss: 12.8241\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "#Lanet Architecture\n",
    "model = Sequential()\n",
    "#Input: 32, 32, 1  Output: 30, 30, 10\n",
    "# model.add(Convolution2D(input_shape=(32, 32, 1)))\n",
    "model.add(Convolution2D(10, 3, 3, subsample=(1, 1), activation='relu' , input_shape=(32, 32, 1)))\n",
    "model.add(Dropout(0.9))\n",
    "#Input: 30, 30, 10 Output: 28, 28, 100 \n",
    "model.add(Convolution2D(100, 3, 3, subsample=(1, 1), activation='relu'))\n",
    "#Max Pooling Input: 28, 28, 100 Output 14, 14, 100\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "#Input: 14, 14, 100 Output: 10, 10, 150\n",
    "model.add(Convolution2D(150, 5, 5, subsample=(1,1), activation= 'relu'))\n",
    "model.add(Dropout(0.8))\n",
    "#Max Pooling Input 10, 10, 150 Output: 5, 5, 150\n",
    "model.add(MaxPooling2D(2,2))\n",
    "#Input 5, 5, 150 Output 4, 4, 250\n",
    "model.add(Convolution2D(250, 2, 2,subsample=(1,1), activation= 'relu'))\n",
    "model.add(Dropout(0.7))\n",
    "#Max Pooling Input 4, 4, 250 Output: 2, 2, 250\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "#Input 2, 2, 250 Output: 1, 1, 1000\n",
    "model.add(Convolution2D(1000, 2, 2,subsample=(1,1), activation= 'relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(Dense(300))\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(n_classes))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X_train, y_train, nb_epoch= 15, validation_split=0.2, batch_size = 120)\n",
    "model.save('model.h5')\n",
    "\n",
    "print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
